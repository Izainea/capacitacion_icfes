<!DOCTYPE html>
<html lang="es">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Lección 5.4: Consumiendo Modelos de Hugging Face</title>
    
    <!-- Google Fonts -->
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Roboto:wght@300;400;700&family=Teko:wght@400;600&display=swap" rel="stylesheet">

    <!-- Font Awesome for Icons -->
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css">

    <style>
        :root {
            --bg-color: #121212;
            --card-bg: #1e1e1e;
            --primary-color: #ff9900; /* AWS Orange */
            --secondary-color: #232f3e; /* AWS Dark Blue */
            --text-color: #e0e0e0;
            --text-muted: #a0a0a0;
            --border-color: #333;
            --success-color: #28a745;
            --info-color: #5dade2;
            --python-color: #3776AB; /* Python Blue */
        }

        html { scroll-behavior: smooth; }

        body {
            font-family: 'Roboto', sans-serif;
            background-color: var(--bg-color);
            color: var(--text-color);
            margin: 0;
            padding: 40px 20px;
            text-align: center;
            overflow-x: hidden;
        }

        .container {
            max-width: 1200px;
            margin: auto;
        }

        h1, h2, h3 {
            font-family: 'Teko', sans-serif;
            font-weight: 600;
            letter-spacing: 1px;
        }

        h1 {
            font-size: 4.5rem;
            color: var(--primary-color);
            margin-bottom: 0;
        }
        
        h2 {
            font-size: 3rem;
            color: var(--text-color);
            border-bottom: 2px solid var(--primary-color);
            display: inline-block;
            padding-bottom: 10px;
            margin-top: 80px;
        }

        .subtitle {
            font-size: 1.6rem;
            color: var(--text-muted);
            margin-top: 0;
            margin-bottom: 80px;
        }

        .section {
            margin-bottom: 100px;
        }

        p {
            font-size: 1.2rem;
            line-height: 1.7;
            color: var(--text-muted);
            max-width: 800px;
            margin: 20px auto 40px;
            text-align: left;
        }
        .center-p {
             text-align: center;
        }
        
        pre {
            background-color: #0d1117;
            border: 1px solid var(--border-color);
            border-radius: 8px;
            padding: 20px;
            text-align: left;
            font-family: 'Courier New', Courier, monospace;
            font-size: 1rem;
            white-space: pre-wrap;
            word-wrap: break-word;
            color: #c9d1d9;
        }
        
        .step-guide {
            text-align: left;
            max-width: 900px;
            margin: 40px auto;
        }
        .step {
            background: var(--card-bg);
            padding: 30px;
            border-radius: 15px;
            margin-bottom: 30px;
            border-left: 4px solid var(--primary-color);
        }
        .step h3 {
            font-size: 2.2rem;
            color: var(--primary-color);
            margin-top: 0;
        }
        
        .info-box {
            background: rgba(55, 118, 171, 0.1);
            border-left: 5px solid var(--python-color);
            padding: 20px;
            border-radius: 10px;
            text-align: left;
            margin-top: 30px;
        }
        .info-box h4 {
            margin-top: 0;
            font-size: 1.8rem;
            color: var(--python-color);
        }
        .info-box p, .info-box ul {
            margin: 10px 0 0 0;
            font-size: 1.1rem;
        }
        
        .navigation-section {
            background: var(--secondary-color); padding: 60px 30px; border-radius: 15px; margin-top: 80px;
        }
        .navigation-section h2 { border: none; }
        .nav-buttons {
            display: flex; justify-content: center; gap: 20px; margin-top: 30px; flex-wrap: wrap;
        }
        .nav-button {
            padding: 15px 30px; border: none; border-radius: 50px; font-size: 1.2rem; font-weight: bold; text-decoration: none;
            transition: transform 0.3s, box-shadow 0.3s; display: inline-flex; align-items: center; gap: 10px; cursor: pointer;
        }
        .back-button {
            background-color: var(--card-bg); color: var(--primary-color); border: 2px solid var(--primary-color);
        }
        .next-button {
            background-color: var(--primary-color); color: var(--secondary-color);
        }
        .next-button.disabled {
            background-color: var(--border-color); color: var(--text-muted); cursor: not-allowed;
        }
        .nav-button:hover:not(.disabled) {
            transform: scale(1.05); box-shadow: 0 5px 20px rgba(0,0,0,0.5);
        }
    </style>
</head>
<body>

    <div class="container">

        <header>
            <h1>Consumiendo Modelos de Hugging Face</h1>
            <p class="subtitle center-p">Expandiendo Fronteras: Integrando la Potencia de Python en tu App Shiny.</p>
        </header>

        <main>
            <section class="section" id="introduccion">
                <h2>¿Por Qué Ir Más Allá de R?</h2>
                <p>
                    Hemos demostrado que R y Shiny son un ecosistema increíblemente poderoso para crear productos de datos de principio a fin. Sin embargo, en el mundo del Machine Learning, gran parte de la innovación y los modelos de última generación (State-of-the-Art), especialmente en Procesamiento del Lenguaje Natural (NLP) y Visión por Computadora, se publican primero en Python.
                </p>
                <p>
                    <b>Hugging Face</b> se ha convertido en el "GitHub de los modelos de ML", un repositorio central donde la comunidad comparte miles de modelos pre-entrenados listos para usar. ¿Significa esto que debemos abandonar R para usarlos? ¡Absolutamente no! Un principio clave de MLOps es que nuestra aplicación debe ser un <b>centro de integración</b>, capaz de consumir inteligencia sin importar dónde fue creada.
                </p>
            </section>
            
            <section class="section" id="reticulate">
                <h2>El Puente Mágico: El Paquete `reticulate`</h2>
                <p>
                    La clave para conectar los mundos de R y Python es el paquete `reticulate`. Esta librería es una de las proezas de ingeniería más impresionantes del ecosistema de R. Permite a R y Python "hablar" entre sí de forma fluida. Con `reticulate`, podemos:
                </p>
                <ul>
                    <li style="text-align: left; font-size: 1.2rem; margin-bottom: 15px;">Importar cualquier librería de Python en nuestra sesión de R.</li>
                    <li style="text-align: left; font-size: 1.2rem; margin-bottom: 15px;">Llamar a funciones de Python directamente desde R.</li>
                    <li style="text-align: left; font-size: 1.2rem;">Convertir objetos (como dataframes y listas) entre R y Python de forma automática.</li>
                </ul>
                <p>
                    `reticulate` es el puente que nos permite construir una interfaz de usuario amigable en Shiny mientras consumimos la potencia de los modelos de Hugging Face en segundo plano.
                </p>
            </section>

            <section class="section" id="taller">
                <h2>Taller: Añadir un Analizador de Sentimientos a la App</h2>
                <p class="center-p">Vamos a añadir una nueva funcionalidad a nuestra app: un analizador que determine si un texto es POSITIVO, NEGATIVO o NEUTRAL, usando un modelo de Hugging Face.</p>
                <div class="step-guide">
                    <div class="step">
                        <h3>Paso 1: Configurar el Entorno de Python con `reticulate`</h3>
                        <p>El primer paso es asegurarnos de que R pueda encontrar una instalación de Python y las librerías necesarias. `reticulate` nos ayuda a gestionar esto.</p>
                        <p><b>Acción:</b> Ejecuta estos comandos en tu consola de R. Solo necesitas hacerlo una vez por proyecto.</p>
                        <pre><code># 1. Instalar reticulate si no se tiene
install.packages("reticulate")

# 2. Instalar las librerías de Python necesarias (transformers y PyTorch)
# reticulate se encargará de crear un entorno virtual para no afectar tu sistema
reticulate::py_install(c("transformers", "torch"))
</code></pre>
                    </div>

                    <div class="step">
                        <h3>Paso 2: Cargar el Pipeline de Hugging Face en `global.R`</h3>
                        <p>Al igual que con nuestro modelo de R, cargaremos el modelo de Hugging Face una sola vez al inicio de la aplicación para máxima eficiencia. Usaremos un modelo entrenado específicamente para varios idiomas, incluido el español.</p>
                        <p><b>Acción:</b> Añade este bloque de código a tu `global.R`.</p>
                        <pre><code># En global.R

# --- Configuración del Entorno Python ---
library(reticulate)

# Importamos la librería 'transformers' de Python a un objeto de R
transformers <- import("transformers")

# Creamos el pipeline de análisis de sentimientos, especificando un modelo multilingüe.
# La primera vez que se ejecute, descargará el modelo (puede tardar un poco).
sentiment_pipeline <- transformers$pipeline(
  "sentiment-analysis", 
  model="cardiffnlp/twitter-roberta-base-sentiment-latest"
)

message("==> Pipeline de Hugging Face cargado y listo.")
</code></pre>
                    </div>

                     <div class="step">
                        <h3>Paso 3: Crear la UI del Analizador en `ui.R`</h3>
                        <p>Añadiremos una nueva pestaña para nuestra herramienta de NLP.</p>
                        <p><b>Acción:</b> Añade este `tabPanel` a tu `ui.R`, dentro del `tabsetPanel`.</p>
                        <pre><code># En ui.R, dentro del tabsetPanel(...)

tabPanel("Análisis de Sentimiento (NLP)",
    fluidPage(
        h3("Analizador de Texto con Hugging Face"),
        p("Escribe un texto en español o inglés y el modelo predecirá si el sentimiento es positivo, negativo o neutral."),
        textAreaInput("nlp_text_input", "Ingresa tu texto aquí:", "Me encanta este curso, es increíble.", rows = 4),
        actionButton("run_nlp", "Analizar Sentimiento", icon = icon("robot"), class = "btn-info"),
        hr(),
        h4("Resultado del Análisis:"),
        verbatimTextOutput("nlp_result")
    )
)
</code></pre>
                    </div>

                    <div class="step">
                        <h3>Paso 4: Implementar la Lógica de Inferencia en `server.R`</h3>
                        <p>Finalmente, conectamos la UI al pipeline de Python que ya tenemos cargado en memoria, traduciendo las etiquetas del modelo a un formato legible.</p>
                        <p><b>Acción:</b> Añade este bloque de código a tu `server.R`.</p>
                        <pre><code># En server.R

# --- Lógica del Análisis de Sentimiento ---

sentiment_result <- eventReactive(input$run_nlp, {
    # Validamos que el usuario haya ingresado texto
    validate(
        need(input$nlp_text_input != "", "Por favor, ingresa un texto para analizar.")
    )

    # ¡La magia de reticulate!
    # Pasamos el texto de R directamente al objeto del pipeline de Python.
    resultado_python <- sentiment_pipeline(input$nlp_text_input)
    
    # Mapeamos la etiqueta del modelo a un texto en español
    label_raw <- resultado_python[[1]]$label
    label_es <- case_when(
        label_raw == "Positive" ~ "POSITIVO",
        label_raw == "Neutral"  ~ "NEUTRAL",
        label_raw == "Negative" ~ "NEGATIVO",
        TRUE ~ label_raw # En caso de que haya una etiqueta inesperada
    )
    
    score <- round(resultado_python[[1]]$score * 100, 2)
    
    return(paste0("Sentimiento Predicho: ", label_es, "\nConfianza: ", score, "%"))
})

output$nlp_result <- renderText({
    sentiment_result()
})
</code></pre>
                         <div class="info-box">
                           <h4><i class="fa-solid fa-cogs"></i> ¡Una App Políglota!</h4>
                           <p>¡Lo has logrado! Tu aplicación Shiny ahora es un verdadero centro de integración. En una misma app, estás consumiendo un modelo de regresión lineal nativo de R y un modelo de Procesamiento de Lenguaje Natural de última generación de Python, demostrando el verdadero poder de una arquitectura MLOps desacoplada.</p>
                        </div>
                    </div>
                </div>
            </section>
            
            <section class="section navigation-section">
                <h2>¡Fin del Módulo 5!</h2>
                <p class="center-p">Has dominado el arte de la integración de modelos, tanto nativos de R como del vasto ecosistema de Python. Tu capacidad para construir productos de datos se ha expandido enormemente.</p>
                <div class="nav-buttons">
                    <a href="simulador_interactivo.html" class="nav-button back-button"><i class="fa-solid fa-arrow-left"></i> Lección 5.3: Simulador</a>
                    <a href="sesion_6.html" class="nav-button next-button">Siguiente Módulo <i class="fa-solid fa-arrow-right"></i></a>
                </div>
            </section>
        </main>
    </div>

</body>
</html>